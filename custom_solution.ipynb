{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b32dc70",
   "metadata": {},
   "source": [
    "# Практическое задание курса Light Auto ML. Часть 3 - Custom Solution\n",
    "\n",
    "<details>\n",
    "<summary>Описание задания</summary>\n",
    "\n",
    "Основная задача - выбрать и решить соревнование с платформы Kaggle.com  (http://kaggle.com/) , используя два подхода:\n",
    "1. Подготовить базовое решение (бейзлайн) с помощью Light Auto ML (LAMA)\n",
    "2. Реализовать альтернативное решение без использования LAMA\n",
    "\n",
    "Требования к выбору соревнования\n",
    "- Можно выбрать как текущие, так и прошедшие денежные соревнования\n",
    "- Другие типы соревнований необходимо согласовать с куратором курса\n",
    "- Нельзя использовать простые соревнования типа Titanic\n",
    "\n",
    "Цели проекта\n",
    "- Превзойти результаты бейзлайна на LAMA\n",
    "- Продемонстрировать качественный код\n",
    "- Использовать стандартные подходы к организации кода (например, Pipeline)\n",
    "- Провести качественный EDA\n",
    "- Предоставить подробное описание и обоснование гипотез\n",
    "\n",
    "Критерии оценки\n",
    "1. Анализ целевой переменной (максимум 1 балл)\n",
    "[0.5] Численный анализ:\n",
    "Для регрессии: распределение таргета, поиск аномальных значений\n",
    "Для классификации: распределение количества классов\n",
    "[0.5] Визуализация статистик:\n",
    "- Изолированный анализ\n",
    "- Анализ во временном контексте\n",
    "\n",
    "2. Анализ признаков (максимум 4 балла)\n",
    "[0.5] Типизация признаков (числовые, категориальные, временные) и их распределения\n",
    "[0.5] Выявление аномальных значений\n",
    "[0.5] Анализ зависимостей между признаками\n",
    "[0.5] Анализ пропущенных значений\n",
    "[0.5] Определение важности признаков (корреляции с таргетом)\n",
    "[1.0] Графическая визуализация минимум 3-х пунктов выше\n",
    "[0.5] Анализ возможных преобразований и генерации новых признаков\n",
    "\n",
    "3. Моделирование (максимум 3.5 балла)\n",
    "[0.25] Обоснование стратегии разделения данных (train-test split)\n",
    "Особое внимание уделить предотвращению утечки данных\n",
    "[0.25] LAMA бейзлайн:\n",
    "- Минимум 2 различные конфигурации\n",
    "- Выбор лучшего решения\n",
    "[3.0] Собственное решение (если не удалось побить LLama baseline: 3 x 1.0 балл за различные пайплайны/попытки):\n",
    "- Выбор модели\n",
    "- Построение пайплайна (препроцессинг, обработка пропусков, генерация признаков, отбор признаков, финальная модель/ансамбль)\n",
    "- Оптимизация гиперпараметров\n",
    "\n",
    "4. Общие требования к коду (максимум 1.5 балла)\n",
    "[0.5] Чистый код:\n",
    "- Оформление ноутбука\n",
    "- Соответствие PEP 8\n",
    "- Правильное именование переменных и функций\n",
    "- Документирование функций\n",
    "[0.5] Качество кода:\n",
    "- Следование принципам SOLID\n",
    "- Отсутствие спагетти-кода\n",
    "- Обработка предупреждений и ошибок\n",
    "- Логгирование\n",
    "[0.5] Структура решения:\n",
    "- Оформление в виде self-contained pipeline\n",
    "- Использование стандартных инструментов (например, sklearn pipeline)\n",
    "\n",
    "Итоговая оценка\n",
    "Максимальный балл: 10\n",
    "9-10 баллов: оценка 5А\n",
    "7-8.5 баллов: оценка 4В\n",
    "5-6.5 баллов: оценка 3D\n",
    "Менее 5 баллов: требуется пересдача\n",
    "\n",
    "Ожидания\n",
    "Работа должна представлять собой мини-исследование с:\n",
    "1) Проработкой и проверкой гипотез\n",
    "2) Оценкой результатов\n",
    "3) Обоснованием выбора пайплайна\n",
    "4) Документированием процесса исследования\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8821b2b",
   "metadata": {},
   "source": [
    "### Часть 3 - Custom Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37619362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# импорт нужных библиотек\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GroupKFold\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor, early_stopping\n",
    "import optuna\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ec579bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной выборки: (6036000, 8)\n",
      "Размер тестовой выборки: (4024000, 7)\n",
      "Размер sample выборки: (4024000, 2)\n"
     ]
    }
   ],
   "source": [
    "# загрузка данных\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "sample = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "print(f\"Размер тренировочной выборки: {train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {test.shape}\")\n",
    "print(f\"Размер sample выборки: {sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d0a3b",
   "metadata": {},
   "source": [
    "##### **3.1 Генерации новых признаков**\n",
    "\n",
    "Вспомним наш стек добавочных признаков:\n",
    "\n",
    "**1. Lag-признаки**\n",
    "- `u_in_lag_1/2/3` - предыдущие значения управляющего сигнала\n",
    "- так как корреляция внутри циклов в 2-3 раза сильнее глобальной\n",
    "\n",
    "**2. Difference признаки**\n",
    "- `u_in_diff` - скорость изменения управляющего сигнала\n",
    "- динамика изменений критична для временных моделей\n",
    "\n",
    "**3. Cumulative sum**\n",
    "- `u_in_cumsum` - накопленный объем воздуха\n",
    "-  физический смысл - интеграл потока\n",
    "\n",
    "**4. Взаимодействия R×C**\n",
    "- `R_x_C` - произведение параметров легких\n",
    "- график показал нелинейное влияние комбинаций\n",
    "\n",
    "**5. Позиция в цикле**\n",
    "- `time_position` - порядковый номер шага внутри breath_id (0-79)\n",
    "- позволяет модели определять фазу дыхания независимо от абсолютного времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1c9cb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 7 new features\n",
      "Всего признаков: 12\n",
      "   Оригинальные: 5\n",
      "   Новые: 7\n",
      "\n",
      "Новые признаки: ['u_in_lag_1', 'u_in_lag_2', 'u_in_lag_3', 'u_in_diff', 'u_in_cumsum', 'R_x_C', 'time_position']\n"
     ]
    }
   ],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Создание признаков на основе анализа:\n",
    "    - Lag features\n",
    "    - Difference\n",
    "    - Cumulative sum\n",
    "    - R×C interaction\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    for lag in [1, 2, 3]:\n",
    "        df[f'u_in_lag_{lag}'] = df.groupby('breath_id')['u_in'].shift(lag)\n",
    "\n",
    "    df['u_in_diff'] = df.groupby('breath_id')['u_in'].diff()\n",
    "    df['u_in_cumsum'] = df.groupby('breath_id')['u_in'].cumsum()\n",
    "    df['R_x_C'] = df['R'] * df['C']\n",
    "    df['time_position'] = df.groupby('breath_id').cumcount()\n",
    "    \n",
    "    # Заполнение NaN в lag-признаках нулями\n",
    "    lag_cols = [f'u_in_lag_{i}' for i in [1, 2, 3]] + ['u_in_diff']\n",
    "    df[lag_cols] = df[lag_cols].fillna(0)\n",
    "    \n",
    "    print(f\"Created {len(lag_cols) + 3} new features\")\n",
    "    return df\n",
    "\n",
    "train_fe = create_features(train)\n",
    "\n",
    "# Список всех признаков\n",
    "ORIGINAL_FEATURES = ['R', 'C', 'time_step', 'u_in', 'u_out']\n",
    "NEW_FEATURES = ['u_in_lag_1', 'u_in_lag_2', 'u_in_lag_3', \n",
    "                'u_in_diff', 'u_in_cumsum', 'R_x_C', 'time_position']\n",
    "ALL_FEATURES = ORIGINAL_FEATURES + NEW_FEATURES\n",
    "\n",
    "print(f\"Всего признаков: {len(ALL_FEATURES)}\")\n",
    "print(f\"   Оригинальные: {len(ORIGINAL_FEATURES)}\")\n",
    "print(f\"   Новые: {len(NEW_FEATURES)}\")\n",
    "print(f\"\\nНовые признаки: {NEW_FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bf149ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 7 new features\n",
      "Created 7 new features\n"
     ]
    }
   ],
   "source": [
    "train_fe = create_features(train)\n",
    "test_fe  = create_features(test)\n",
    "\n",
    "FEATURES = ['R','C','time_step','u_in','u_out','u_in_lag_1','u_in_lag_2','u_in_lag_3',\n",
    "            'u_in_diff','u_in_cumsum','R_x_C','time_position']\n",
    "TARGET = 'pressure'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b3cea",
   "metadata": {},
   "source": [
    "### **3.2 Выбор модели и стратегия валидации**\n",
    "\n",
    "**Почему выбор упарл на LightGBM?**\n",
    "1. **Результаты LAMA**: LightGBM показал лучшие результаты в LAMA экспериментах\n",
    "2. **Скорость обучения**: быстрее CatBoost, что критично для Optuna оптимизации и эффективно работает с большими данными (более 6М+ строк)\n",
    "3. **Встроенная обработка категориальных признаков**: R, C, u_out\n",
    "\n",
    "**Стратегия валидации: GroupKFold**\n",
    "- **5 фолдов** по breath_id - целые циклы дыхания не пересекаются между train/val\n",
    "- **Предотвращение утечки**: модель не видит другие шаги того же цикла во время валидации\n",
    "- **Метрика**: MAE\n",
    "\n",
    "**Early Stopping**\n",
    "- Остановка обучения через 100 итераций без улучшения\n",
    "- Защита от переобучения\n",
    "- Ускорение Optuna (не обучаем плохие конфигурации до конца)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9920f",
   "metadata": {},
   "source": [
    "**Оптимизируемые параметры:**\n",
    "- `learning_rate`: 0.01 - 0.1 (log scale) - скорость обучения\n",
    "- `num_leaves`: 31 - 128 - сложность деревьев\n",
    "- `subsample`: 0.6 - 1.0 - доля строк для обучения каждого дерева\n",
    "- `colsample_bytree`: 0.6 - 1.0 - доля признаков для каждого дерева\n",
    "\n",
    "**Фиксированные параметры:**\n",
    "- `n_estimators`: 4000 - максимальное число деревьев (с early stopping)\n",
    "- `random_state`: 42 - воспроизводимость\n",
    "\n",
    "**Настройки Optuna:**\n",
    "- 15 trials - компромисс между качеством и временем\n",
    "- 1800 секунд timeout - максимум 30 минут\n",
    "- Минимизация OOF MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e7b87",
   "metadata": {},
   "source": [
    "##### A. Новый вариант с cross_val_score  + early_stopping + LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем валидационный сет исключительно для этого варианта\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(train_fe, groups=train_fe['breath_id']))\n",
    "\n",
    "X_train = train_fe.iloc[train_idx][FEATURES]\n",
    "y_train = train_fe.iloc[train_idx][TARGET]\n",
    "\n",
    "X_val = train_fe.iloc[val_idx][FEATURES]\n",
    "y_val = train_fe.iloc[val_idx][TARGET]\n",
    "\n",
    "groups_train = train_fe.iloc[train_idx]['breath_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8006e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-31 00:28:50,919] A new study created in memory with name: no-name-314cb6d6-af98-4a5c-91ef-aef70410ce7d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.220706\n",
      "[LightGBM] [Info] Start training from score 11.216512\n",
      "[LightGBM] [Info] Start training from score 11.217725\n",
      "[LightGBM] [Info] Start training from score 11.227754\n",
      "[LightGBM] [Info] Start training from score 11.219441\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.510184\tvalid_0's l2: 0.812592\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.509165\tvalid_0's l2: 0.809788\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.510078\tvalid_0's l2: 0.811034\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.510358\tvalid_0's l2: 0.812789\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.510039\tvalid_0's l2: 0.838218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-31 00:41:27,448] Trial 0 finished with value: 0.5158440473966881 and parameters: {'learning_rate': 0.038346540556094974, 'num_leaves': 119, 'subsample': 0.7365705298918935, 'colsample_bytree': 0.7646452608285308}. Best is trial 0 with value: 0.5158440473966881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.220706\n",
      "[LightGBM] [Info] Start training from score 11.219441\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.116251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.216512\n",
      "[LightGBM] [Info] Start training from score 11.227754\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Info] Start training from score 11.217725\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.614211\tvalid_0's l2: 1.15663\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.614709\tvalid_0's l2: 1.12381\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.614313\tvalid_0's l2: 1.13042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.613212\tvalid_0's l2: 1.1256\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.613287\tvalid_0's l2: 1.12995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-31 00:52:01,815] Trial 1 finished with value: 0.6222257345565322 and parameters: {'learning_rate': 0.015695404994591627, 'num_leaves': 63, 'subsample': 0.6409757352945158, 'colsample_bytree': 0.6371299265500254}. Best is trial 0 with value: 0.5158440473966881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.220706\n",
      "[LightGBM] [Info] Start training from score 11.217725\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 3863040, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.216512\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Info] Start training from score 11.219441\n",
      "[LightGBM] [Info] Start training from score 11.227754\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.55837\tvalid_0's l2: 0.938124\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.560088\tvalid_0's l2: 0.94596\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.558106\tvalid_0's l2: 0.961968\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.558953\tvalid_0's l2: 0.94116\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.559566\tvalid_0's l2: 0.942031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-31 00:59:51,322] Trial 2 finished with value: 0.5656365151522015 and parameters: {'learning_rate': 0.03780269167918193, 'num_leaves': 50, 'subsample': 0.6716679412529537, 'colsample_bytree': 0.915971920569901}. Best is trial 0 with value: 0.5158440473966881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.038346540556094974, 'num_leaves': 119, 'subsample': 0.7365705298918935, 'colsample_bytree': 0.7646452608285308}\n",
      "Best OOF MAE: 0.5158440473966881\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': 4000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 128),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "\n",
    "    mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    gkf = GroupKFold(n_splits=5, random_state=42)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups=groups_train,\n",
    "        cv=gkf,\n",
    "        scoring=mae_scorer,\n",
    "        params={\n",
    "            \"eval_set\": [(X_val, y_val)],\n",
    "            \"eval_metric\": \"mae\",\n",
    "            \"callbacks\": [early_stopping(stopping_rounds=100)]\n",
    "        },\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return -scores.mean()\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15, timeout=1800)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best OOF MAE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaefbed",
   "metadata": {},
   "source": [
    "##### B. Новый вариант с cross_val_score + LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-30 19:40:00,293] A new study created in memory with name: no-name-74a04cc5-e8fd-4fb0-98d4-a9da191da1aa\n",
      "/var/folders/rf/r9_1j8lj3m72m2lv3v1tp3rh0000gn/T/ipykernel_61214/235241336.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
      "/var/folders/rf/r9_1j8lj3m72m2lv3v1tp3rh0000gn/T/ipykernel_61214/235241336.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "/var/folders/rf/r9_1j8lj3m72m2lv3v1tp3rh0000gn/T/ipykernel_61214/235241336.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.266543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.223842\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Start training from score 11.225156\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.224218\n",
      "[LightGBM] [Info] Start training from score 11.207507\n",
      "[LightGBM] [Info] Start training from score 11.221318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-30 19:50:01,359] Trial 0 finished with value: 0.5633654128733779 and parameters: {'learning_rate': 0.02853590335634323, 'num_leaves': 64, 'subsample': 0.6531058513704433, 'colsample_bytree': 0.9318078793865102}. Best is trial 0 with value: 0.5633654128733779.\n",
      "/var/folders/rf/r9_1j8lj3m72m2lv3v1tp3rh0000gn/T/ipykernel_61214/235241336.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
      "/var/folders/rf/r9_1j8lj3m72m2lv3v1tp3rh0000gn/T/ipykernel_61214/235241336.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "/var/folders/rf/r9_1j8lj3m72m2lv3v1tp3rh0000gn/T/ipykernel_61214/235241336.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.225156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.221318\n",
      "[LightGBM] [Info] Start training from score 11.224218\n",
      "[LightGBM] [Info] Start training from score 11.223842\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.146875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.207507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-30 19:59:01,387] Trial 1 finished with value: 0.5232370180050429 and parameters: {'learning_rate': 0.08496274730236524, 'num_leaves': 60, 'subsample': 0.6008482099306177, 'colsample_bytree': 0.6224201140927726}. Best is trial 1 with value: 0.5232370180050429.\n",
      "/var/folders/rf/r9_1j8lj3m72m2lv3v1tp3rh0000gn/T/ipykernel_61214/235241336.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
      "/var/folders/rf/r9_1j8lj3m72m2lv3v1tp3rh0000gn/T/ipykernel_61214/235241336.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "/var/folders/rf/r9_1j8lj3m72m2lv3v1tp3rh0000gn/T/ipykernel_61214/235241336.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.223842\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.225156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.224218\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.221318\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1884\n",
      "[LightGBM] [Info] Number of data points in the train set: 4828800, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.207507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-30 20:11:52,452] Trial 2 finished with value: 0.494887009625485 and parameters: {'learning_rate': 0.05332723976196547, 'num_leaves': 123, 'subsample': 0.8591690890817245, 'colsample_bytree': 0.7140709673483161}. Best is trial 2 with value: 0.494887009625485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.05332723976196547, 'num_leaves': 123, 'subsample': 0.8591690890817245, 'colsample_bytree': 0.7140709673483161}\n",
      "Best OOF MAE: 0.494887009625485\n"
     ]
    }
   ],
   "source": [
    "# def objective(trial):\n",
    "#     # параметры для Optuna\n",
    "#     params = {\n",
    "#         'n_estimators': 4000,\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 31, 128),\n",
    "#         'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "#         'random_state': 42,\n",
    "#         'n_jobs': -1\n",
    "#     }\n",
    "    \n",
    "#     model = LGBMRegressor(**params)\n",
    "#     mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "#     gkf = GroupKFold(n_splits=5, random_state=42)\n",
    "    \n",
    "#     # cross_val_score с группами\n",
    "#     scores = cross_val_score(\n",
    "#         model,\n",
    "#         train_fe[FEATURES],\n",
    "#         train_fe[TARGET],\n",
    "#         groups=train_fe['breath_id'], # по циклам дыхания\n",
    "#         cv=gkf,\n",
    "#         scoring=mae_scorer,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "    \n",
    "#     # возвращаем среднюю MAE по фолдам (минус для положительного числа)\n",
    "#     return -scores.mean()\n",
    "\n",
    "\n",
    "# # Run Optuna\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=15, timeout=1800)  # до 30 минут\n",
    "\n",
    "# print(\"Best params:\", study.best_params)\n",
    "# print(\"Best OOF MAE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cee6003",
   "metadata": {},
   "source": [
    "#### C. Первоночальный вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a17f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optuna\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'n_estimators': 4000,\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 31, 128),\n",
    "#         'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "#         'random_state': 42,\n",
    "#         'n_jobs': -1\n",
    "#     }\n",
    "    \n",
    "#     oof = np.zeros(len(train_fe))\n",
    "#     gkf = GroupKFold(n_splits=5, random_state=42)\n",
    "    \n",
    "#     for tr_idx, val_idx in gkf.split(train_fe, groups=train_fe['breath_id']):\n",
    "#         X_tr, X_val = train_fe.iloc[tr_idx][FEATURES], train_fe.iloc[val_idx][FEATURES]\n",
    "#         y_tr, y_val = train_fe.iloc[tr_idx][TARGET], train_fe.iloc[val_idx][TARGET]\n",
    "        \n",
    "#         model = LGBMRegressor(**params)\n",
    "#         model.fit(\n",
    "#             X_tr, y_tr,\n",
    "#             eval_set=[(X_val, y_val)],\n",
    "#             eval_metric='mae',\n",
    "#             callbacks=[early_stopping(stopping_rounds=100)]\n",
    "#         )\n",
    "#         oof[val_idx] = model.predict(X_val)\n",
    "    \n",
    "#     return mean_absolute_error(train_fe[TARGET], oof)\n",
    "\n",
    "\n",
    "# # Run Optuna\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=15, timeout=1800)  # до 30 минут\n",
    "\n",
    "# print(\"Best params:\", study.best_params)\n",
    "# print(\"Best OOF MAE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2eb603",
   "metadata": {},
   "source": [
    "##### D. Новый варинат с моделью из sclearn HistGradientBoostingRegressor\n",
    "так как здесь удобно использовать cross_val_score + early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-31 01:59:29,104] A new study created in memory with name: no-name-e8fd9ceb-4747-439c-964c-ba62be0911a0\n",
      "/Users/anastasia/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/anastasia/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/anastasia/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/anastasia/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/anastasia/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "[I 2025-12-31 02:10:08,458] Trial 0 finished with value: 0.6096259151027871 and parameters: {'learning_rate': 0.04991085842652048, 'max_leaf_nodes': 31, 'min_samples_leaf': 39, 'max_depth': 6}. Best is trial 0 with value: 0.6096259151027871.\n",
      "/Users/anastasia/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/anastasia/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/anastasia/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "[I 2025-12-31 08:47:38,359] Trial 1 finished with value: 0.5520620022838456 and parameters: {'learning_rate': 0.03571551063552218, 'max_leaf_nodes': 76, 'min_samples_leaf': 50, 'max_depth': 8}. Best is trial 1 with value: 0.5520620022838456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.03571551063552218, 'max_leaf_nodes': 76, 'min_samples_leaf': 50, 'max_depth': 8}\n",
      "Best OOF MAE: 0.5520620022838456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "#         'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 31, 128),\n",
    "#         'max_iter': 4000,\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 20, 100),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'random_state': 42,\n",
    "#         'early_stopping': True,\n",
    "#         'n_iter_no_change': 100,\n",
    "#         'validation_fraction': 0.2\n",
    "#     }\n",
    "#     mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "#     gkf = GroupKFold(n_splits=5, random_state=42)   \n",
    "#     model = HistGradientBoostingRegressor(**params)\n",
    "\n",
    "#     # cross_val_score с группами\n",
    "#     scores = cross_val_score(\n",
    "#         model,\n",
    "#         train_fe[FEATURES],\n",
    "#         train_fe[TARGET],\n",
    "#         groups=train_fe['breath_id'],\n",
    "#         cv=gkf,\n",
    "#         scoring=mae_scorer,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "\n",
    "#     return -scores.mean()\n",
    "\n",
    "# # Запуск Optuna\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=15, timeout=1800)\n",
    "\n",
    "# print(\"Best params:\", study.best_params)\n",
    "# print(\"Best OOF MAE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf37b0",
   "metadata": {},
   "source": [
    "### **3.3 Обучение финальной модели**\n",
    "\n",
    "Используем лучшие параметры из Optuna для обучения на всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d97405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train final model with best params for LGBMRegressor\n",
    "# best_params = study.best_params\n",
    "# best_params['n_estimators'] = 4000\n",
    "# best_params['random_state'] = 42\n",
    "# best_params['n_jobs'] = -1\n",
    "\n",
    "# final_model = LGBMRegressor(**best_params)\n",
    "# final_model.fit(train_fe[FEATURES], train_fe[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1deb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(learning_rate=0.03571551063552218, max_depth=8,\n",
       "                              max_iter=4000, max_leaf_nodes=76,\n",
       "                              min_samples_leaf=50, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>HistGradientBoostingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html\">?<span>Documentation for HistGradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=loss,-%7B%27squared_error%27%2C%20%27absolute_error%27%2C%20%27gamma%27%2C%20%27poisson%27%2C%20%27quantile%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27squared_error%27\">\n",
       "            loss\n",
       "            <span class=\"param-doc-description\">loss: {'squared_error', 'absolute_error', 'gamma', 'poisson', 'quantile'},             default='squared_error'<br><br>The loss function to use in the boosting process. Note that the<br>\"squared error\", \"gamma\" and \"poisson\" losses actually implement<br>\"half least squares loss\", \"half gamma deviance\" and \"half poisson<br>deviance\" to simplify the computation of the gradient. Furthermore,<br>\"gamma\" and \"poisson\" losses internally use a log-link, \"gamma\"<br>requires ``y > 0`` and \"poisson\" requires ``y >= 0``.<br>\"quantile\" uses the pinball loss.<br><br>.. versionchanged:: 0.23<br>   Added option 'poisson'.<br><br>.. versionchanged:: 1.1<br>   Added option 'quantile'.<br><br>.. versionchanged:: 1.3<br>   Added option 'gamma'.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('quantile',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=quantile,-float%2C%20default%3DNone\">\n",
       "            quantile\n",
       "            <span class=\"param-doc-description\">quantile: float, default=None<br><br>If loss is \"quantile\", this parameter specifies which quantile to be estimated<br>and must be between 0 and 1.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=learning_rate,-float%2C%20default%3D0.1\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: float, default=0.1<br><br>The learning rate, also known as *shrinkage*. This is used as a<br>multiplicative factor for the leaves values. Use ``1`` for no<br>shrinkage.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.03571551063552218</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>The maximum number of iterations of the boosting process, i.e. the<br>maximum number of trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">4000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=max_leaf_nodes,-int%20or%20None%2C%20default%3D31\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int or None, default=31<br><br>The maximum number of leaves for each tree. Must be strictly greater<br>than 1. If None, there is no maximum limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">76</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=max_depth,-int%20or%20None%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int or None, default=None<br><br>The maximum depth of each tree. The depth of a tree is the number of<br>edges to go from the root to the deepest leaf.<br>Depth isn't constrained by default.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=min_samples_leaf,-int%2C%20default%3D20\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int, default=20<br><br>The minimum number of samples per leaf. For small datasets with less<br>than a few hundred samples, it is recommended to lower this value<br>since only very shallow trees would be built.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">50</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l2_regularization',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=l2_regularization,-float%2C%20default%3D0\">\n",
       "            l2_regularization\n",
       "            <span class=\"param-doc-description\">l2_regularization: float, default=0<br><br>The L2 regularization parameter penalizing leaves with small hessians.<br>Use ``0`` for no regularization (default).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=max_features,-float%2C%20default%3D1.0\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: float, default=1.0<br><br>Proportion of randomly chosen features in each and every node split.<br>This is a form of regularization, smaller values make the trees weaker<br>learners and might prevent overfitting.<br>If interaction constraints from `interaction_cst` are present, only allowed<br>features are taken into account for the subsampling.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bins',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=max_bins,-int%2C%20default%3D255\">\n",
       "            max_bins\n",
       "            <span class=\"param-doc-description\">max_bins: int, default=255<br><br>The maximum number of bins to use for non-missing values. Before<br>training, each feature of the input array `X` is binned into<br>integer-valued bins, which allows for a much faster training stage.<br>Features with a small number of unique values may use less than<br>``max_bins`` bins. In addition to the ``max_bins`` bins, one more bin<br>is always reserved for missing values. Must be no larger than 255.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">255</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('categorical_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=categorical_features,-array-like%20of%20%7Bbool%2C%20int%2C%20str%7D%20of%20shape%20%28n_features%29%20%20%20%20%20%20%20%20%20%20%20%20%20or%20shape%20%28n_categorical_features%2C%29%2C%20default%3D%27from_dtype%27\">\n",
       "            categorical_features\n",
       "            <span class=\"param-doc-description\">categorical_features: array-like of {bool, int, str} of shape (n_features)             or shape (n_categorical_features,), default='from_dtype'<br><br>Indicates the categorical features.<br><br>- None : no feature will be considered categorical.<br>- boolean array-like : boolean mask indicating categorical features.<br>- integer array-like : integer indices indicating categorical<br>  features.<br>- str array-like: names of categorical features (assuming the training<br>  data has feature names).<br>- `\"from_dtype\"`: dataframe columns with dtype \"category\" are<br>  considered to be categorical features. The input must be an object<br>  exposing a ``__dataframe__`` method such as pandas or polars<br>  DataFrames to use this feature.<br><br>For each categorical feature, there must be at most `max_bins` unique<br>categories. Negative values for categorical features encoded as numeric<br>dtypes are treated as missing values. All categorical values are<br>converted to floating point numbers. This means that categorical values<br>of 1.0 and 1 are treated as the same category.<br><br>Read more in the :ref:`User Guide <categorical_support_gbdt>` and<br>:ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_categorical.py`.<br><br>.. versionadded:: 0.24<br><br>.. versionchanged:: 1.2<br>   Added support for feature names.<br><br>.. versionchanged:: 1.4<br>   Added `\"from_dtype\"` option.<br><br>.. versionchanged:: 1.6<br>   The default value changed from `None` to `\"from_dtype\"`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;from_dtype&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%20or%20dict%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features) or dict, default=None<br><br>Monotonic constraint to enforce on each feature are specified using the<br>following integer values:<br><br>- 1: monotonic increase<br>- 0: no constraint<br>- -1: monotonic decrease<br><br>If a dict with str keys, map feature to monotonic constraints by name.<br>If an array, the features are mapped to constraints by position. See<br>:ref:`monotonic_cst_features_names` for a usage example.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 0.23<br><br>.. versionchanged:: 1.2<br>   Accept dict of constraints with feature names as keys.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=interaction_cst,-%7B%22pairwise%22%2C%20%22no_interactions%22%7D%20or%20sequence%20of%20lists/tuples/sets%20%20%20%20%20%20%20%20%20%20%20%20%20of%20int%2C%20default%3DNone\">\n",
       "            interaction_cst\n",
       "            <span class=\"param-doc-description\">interaction_cst: {\"pairwise\", \"no_interactions\"} or sequence of lists/tuples/sets             of int, default=None<br><br>Specify interaction constraints, the sets of features which can<br>interact with each other in child node splits.<br><br>Each item specifies the set of feature indices that are allowed<br>to interact with each other. If there are more features than<br>specified in these constraints, they are treated as if they were<br>specified as an additional set.<br><br>The strings \"pairwise\" and \"no_interactions\" are shorthands for<br>allowing only pairwise or no interactions, respectively.<br><br>For instance, with 5 features in total, `interaction_cst=[{0, 1}]`<br>is equivalent to `interaction_cst=[{0, 1}, {2, 3, 4}]`,<br>and specifies that each branch of a tree will either only split<br>on features 0 and 1 or only split on features 2, 3 and 4.<br><br>See :ref:`this example<ice-vs-pdp>` on how to use `interaction_cst`.<br><br>.. versionadded:: 1.2</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble. For results to be valid, the<br>estimator should be re-trained on the same data only.<br>See :term:`the Glossary <warm_start>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=early_stopping,-%27auto%27%20or%20bool%2C%20default%3D%27auto%27\">\n",
       "            early_stopping\n",
       "            <span class=\"param-doc-description\">early_stopping: 'auto' or bool, default='auto'<br><br>If 'auto', early stopping is enabled if the sample size is larger than<br>10000 or if `X_val` and `y_val` are passed to `fit`. If True, early stopping<br>is enabled, otherwise early stopping is disabled.<br><br>.. versionadded:: 0.23</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=scoring,-str%20or%20callable%20or%20None%2C%20default%3D%27loss%27\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str or callable or None, default='loss'<br><br>Scoring method to use for early stopping. Only used if `early_stopping`<br>is enabled. Options:<br><br>- str: see :ref:`scoring_string_names` for options.<br>- callable: a scorer callable object (e.g., function) with signature<br>  ``scorer(estimator, X, y)``. See :ref:`scoring_callable` for details.<br>- `None`: the :ref:`coefficient of determination <r2_score>`<br>  (:math:`R^2`) is used.<br>- 'loss': early stopping is checked w.r.t the loss value.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;loss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=validation_fraction,-int%20or%20float%20or%20None%2C%20default%3D0.1\">\n",
       "            validation_fraction\n",
       "            <span class=\"param-doc-description\">validation_fraction: int or float or None, default=0.1<br><br>Proportion (or absolute size) of training data to set aside as<br>validation data for early stopping. If None, early stopping is done on<br>the training data.<br>The value is ignored if either early stopping is not performed, e.g.<br>`early_stopping=False`, or if `X_val` and `y_val` are passed to fit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=n_iter_no_change,-int%2C%20default%3D10\">\n",
       "            n_iter_no_change\n",
       "            <span class=\"param-doc-description\">n_iter_no_change: int, default=10<br><br>Used to determine when to \"early stop\". The fitting process is<br>stopped when none of the last ``n_iter_no_change`` scores are better<br>than the ``n_iter_no_change - 1`` -th-to-last one, up to some<br>tolerance. Only used if early stopping is performed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=tol,-float%2C%20default%3D1e-7\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-7<br><br>The absolute tolerance to use when comparing scores during early<br>stopping. The higher the tolerance, the more likely we are to early<br>stop: higher tolerance means that it will be harder for subsequent<br>iterations to be considered an improvement upon the reference score.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1e-07</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>The verbosity level. If not zero, print some information about the<br>fitting process. ``1`` prints only summary info, ``2`` prints info per<br>iteration.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Pseudo-random number generator to control the subsampling in the<br>binning process, and the train/validation data split if early stopping<br>is enabled.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-4');</script></body>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(learning_rate=0.03571551063552218, max_depth=8,\n",
       "                              max_iter=4000, max_leaf_nodes=76,\n",
       "                              min_samples_leaf=50, random_state=42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train final model with best params\n",
    "best_params = study.best_params\n",
    "best_params['max_iter'] = 4000\n",
    "best_params['random_state'] = 42\n",
    "\n",
    "final_model = HistGradientBoostingRegressor(**best_params)\n",
    "final_model.fit(train_fe[FEATURES], train_fe[TARGET])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c92ef",
   "metadata": {},
   "source": [
    "**Выводы по Feature Importance:**\n",
    "- Наиболее важные признаки - это созданные FE (отмечены [FE])\n",
    "- Lag-признаки (`u_in_lag_X`) оказались критичными для предсказания\n",
    "- Базовые признаки (`u_in`, `u_out`, `time_step`) также играют важную роль\n",
    "- Признак `R_x_C` (взаимодействие параметров легких) подтвердил свою значимость из EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51907948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission file\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pressure",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f2b827af-d1dd-4c0f-b1b0-0cb17429e8a5",
       "rows": [
        [
         "0",
         "1",
         "6.2574618149933885"
        ],
        [
         "1",
         "2",
         "5.938614394626192"
        ],
        [
         "2",
         "3",
         "6.908497077820573"
        ],
        [
         "3",
         "4",
         "7.7015774720721035"
        ],
        [
         "4",
         "5",
         "8.985267715226641"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.257462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.938614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.908497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.701577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.985268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pressure\n",
       "0   1  6.257462\n",
       "1   2  5.938614\n",
       "2   3  6.908497\n",
       "3   4  7.701577\n",
       "4   5  8.985268"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test\n",
    "test_pred = final_model.predict(test_fe[FEATURES])\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'pressure': test_pred\n",
    "})\n",
    "submission.to_csv('submissions/lgbm_fe_optuna_hgbr_submission.csv', index=False)\n",
    "print(\"Saved submission file\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5aa5b6",
   "metadata": {},
   "source": [
    "\n",
    "#### **Итоговые выводы**\n",
    "\n",
    "**Ключевые инсайты:**\n",
    "1. **Feature Engineering критичен** - 7 новых признаков дали основной прирост\n",
    "2. **Lag-признаки важнейшие** - корреляция внутри циклов в 2-3 раза сильнее\n",
    "3. **GroupKFold необходим** - предотвращает утечку данных по breath_id\n",
    "\n",
    "#### **Сравнение с LAMA Baseline и кастомными вариантами (A, B, C, D)**\n",
    "где: \n",
    "- A: вариант с cross_val_score  + early_stopping + LGBM (NEW)\n",
    "- B: вариант с cross_val_score + LGBM (NEW)\n",
    "- **C: вариант со своим циклом по cross_val_score  + early_stopping + LGBM (OLD)**\n",
    "- D: варинат с cross_val_score  + early_stopping + моделью из sclearn HistGradientBoostingRegressor (NEW)\n",
    "\n",
    "| Модель | Признаки | Public | Private |\n",
    "|--------|----------|--------|---------|\n",
    "| **LAMA Config 5** | 12 (5+7 FE) | 0.8480 | 0.8491 |\n",
    "| **Вариант A** | 12 (5+7 FE) | 0.8483 | 0.8471 |\n",
    "| **Вариант B** | 12 (5+7 FE) | 0.8196 | 0.8183 |\n",
    "| **Вариант C** | 12 (5+7 FE) | **0.7761** | **0.779** |\n",
    "| **Вариант D** | 12 (5+7 FE) | 0.9271 | 0.9267 |\n",
    "\n",
    "**Вывод по экспериментам**\n",
    "\n",
    "Были протестированы несколько стратегий обучения и валидации моделей. Использование **cross_val_score** показало себя как удобный и корректный инструмент для быстрой и воспроизводимой оценки качества моделей (варианты **A, B, D**).\n",
    "\n",
    "При этом эксперименты с LightGBM показали, что на данной задаче временных рядов с групповой структурой (breath_id) наилучшее качество достигается при явном контроле обучения на каждом фолде с передачей собственного eval_set и использованием early stopping. Такой подход позволяет модели точнее подстраиваться под динамику внутри дыхательных циклов и даёт более стабильный результат.\n",
    "\n",
    "В итоге именно вариант с ручным циклом по фолдам (**вариант C**) показал наилучшее качество среди всех рассмотренных решений и был выбран как финальный."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd98c66",
   "metadata": {},
   "source": [
    "#### Результаты подтверждения с Kaggle - урезанные (только лучшая lama и кастомные решения)\n",
    "\n",
    "![Kaggle Leaderboard](picture/submissions_best.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ventilator-pressure-prediction-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
