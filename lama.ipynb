{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eba460c",
   "metadata": {},
   "source": [
    "# Практическое задание курса Light Auto ML. Часть 2 - LAMA\n",
    "\n",
    "<details>\n",
    "<summary>Описание задания</summary>\n",
    "\n",
    "Основная задача - выбрать и решить соревнование с платформы Kaggle.com  (http://kaggle.com/) , используя два подхода:\n",
    "1. Подготовить базовое решение (бейзлайн) с помощью Light Auto ML (LAMA)\n",
    "2. Реализовать альтернативное решение без использования LAMA\n",
    "\n",
    "Требования к выбору соревнования\n",
    "- Можно выбрать как текущие, так и прошедшие денежные соревнования\n",
    "- Другие типы соревнований необходимо согласовать с куратором курса\n",
    "- Нельзя использовать простые соревнования типа Titanic\n",
    "\n",
    "Цели проекта\n",
    "- Превзойти результаты бейзлайна на LAMA\n",
    "- Продемонстрировать качественный код\n",
    "- Использовать стандартные подходы к организации кода (например, Pipeline)\n",
    "- Провести качественный EDA\n",
    "- Предоставить подробное описание и обоснование гипотез\n",
    "\n",
    "Критерии оценки\n",
    "1. Анализ целевой переменной (максимум 1 балл)\n",
    "[0.5] Численный анализ:\n",
    "Для регрессии: распределение таргета, поиск аномальных значений\n",
    "Для классификации: распределение количества классов\n",
    "[0.5] Визуализация статистик:\n",
    "- Изолированный анализ\n",
    "- Анализ во временном контексте\n",
    "\n",
    "2. Анализ признаков (максимум 4 балла)\n",
    "[0.5] Типизация признаков (числовые, категориальные, временные) и их распределения\n",
    "[0.5] Выявление аномальных значений\n",
    "[0.5] Анализ зависимостей между признаками\n",
    "[0.5] Анализ пропущенных значений\n",
    "[0.5] Определение важности признаков (корреляции с таргетом)\n",
    "[1.0] Графическая визуализация минимум 3-х пунктов выше\n",
    "[0.5] Анализ возможных преобразований и генерации новых признаков\n",
    "\n",
    "3. Моделирование (максимум 3.5 балла)\n",
    "[0.25] Обоснование стратегии разделения данных (train-test split)\n",
    "Особое внимание уделить предотвращению утечки данных\n",
    "[0.25] LAMA бейзлайн:\n",
    "- Минимум 2 различные конфигурации\n",
    "- Выбор лучшего решения\n",
    "[3.0] Собственное решение (если не удалось побить LLama baseline: 3 x 1.0 балл за различные пайплайны/попытки):\n",
    "- Выбор модели\n",
    "- Построение пайплайна (препроцессинг, обработка пропусков, генерация признаков, отбор признаков, финальная модель/ансамбль)\n",
    "- Оптимизация гиперпараметров\n",
    "\n",
    "4. Общие требования к коду (максимум 1.5 балла)\n",
    "[0.5] Чистый код:\n",
    "- Оформление ноутбука\n",
    "- Соответствие PEP 8\n",
    "- Правильное именование переменных и функций\n",
    "- Документирование функций\n",
    "[0.5] Качество кода:\n",
    "- Следование принципам SOLID\n",
    "- Отсутствие спагетти-кода\n",
    "- Обработка предупреждений и ошибок\n",
    "- Логгирование\n",
    "[0.5] Структура решения:\n",
    "- Оформление в виде self-contained pipeline\n",
    "- Использование стандартных инструментов (например, sklearn pipeline)\n",
    "\n",
    "Итоговая оценка\n",
    "Максимальный балл: 10\n",
    "9-10 баллов: оценка 5А\n",
    "7-8.5 баллов: оценка 4В\n",
    "5-6.5 баллов: оценка 3D\n",
    "Менее 5 баллов: требуется пересдача\n",
    "\n",
    "Ожидания\n",
    "Работа должна представлять собой мини-исследование с:\n",
    "1) Проработкой и проверкой гипотез\n",
    "2) Оценкой результатов\n",
    "3) Обоснованием выбора пайплайна\n",
    "4) Документированием процесса исследования\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a3650",
   "metadata": {},
   "source": [
    "#### **Импорт нужных библиотек**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46ffb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797d2b7",
   "metadata": {},
   "source": [
    "## 3. Моделирование\n",
    "\n",
    "##### **Повторная загрузка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83008d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной выборки: (6036000, 8)\n",
      "Размер тестовой выборки: (4024000, 7)\n",
      "Размер sample выборки: (4024000, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "sample = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "print(f\"Размер тренировочной выборки: {train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {test.shape}\")\n",
    "print(f\"Размер sample выборки: {sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c88cae3",
   "metadata": {},
   "source": [
    "#### **ВАРИАНТ 1**\n",
    "##### **3.1 Разделение данных - Проверка теории** \n",
    "- Обоснование стратегии разделения данных (train-test split)\n",
    "- Особое внимание уделить предотвращению утечки данных\n",
    "\n",
    "\n",
    "**Особенности данных:**\n",
    "- Временные ряды с breath_id (циклы дыхания по 80 шагов)\n",
    "- Риск утечки данных при случайном split\n",
    "\n",
    "**Стратегия:**\n",
    "Используем **GroupShuffleSplit** по breath_id - целые циклы попадают либо в train, либо в validation, но не в оба набора.\n",
    "\n",
    "**Обоснование:**\n",
    "Если разделить breath_id между train/val, модель увидит часть цикла и будет предсказывать другую часть того же цикла → завышенное качество из-за утечки.\n",
    "\n",
    "**Разделение:** 80% train / 20% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4004f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4828800 строк, 60360 циклов\n",
      "Val: 1207200 строк, 15090 циклов\n",
      "Пересечение breath_id: 0\n"
     ]
    }
   ],
   "source": [
    "# # Признаки: ТОЛЬКО ОРИГИНАЛЬНЫЕ для baseline\n",
    "FEATURES = ['R', 'C', 'time_step', 'u_in', 'u_out']\n",
    "TARGET = 'pressure'\n",
    "\n",
    "# Разделение по breath_id\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(train, groups=train['breath_id']))\n",
    "\n",
    "X_train = train.iloc[train_idx]\n",
    "X_val = train.iloc[val_idx]\n",
    "\n",
    "print(f\"Train: {len(X_train)} строк, {X_train['breath_id'].nunique()} циклов\")\n",
    "print(f\"Val: {len(X_val)} строк, {X_val['breath_id'].nunique()} циклов\")\n",
    "print(f\"Пересечение breath_id: {len(set(X_train['breath_id']) & set(X_val['breath_id']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d49e4",
   "metadata": {},
   "source": [
    "#### **3.2 LAMA бейзлайн на пяти конфигурациях**\n",
    "##### **Config_1. LAMA бейзлайн – FAST + split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LAMA CONFIG 1: FAST (300 sec)\")\n",
    "\n",
    "task = Task('reg', metric='mae')\n",
    "automl_fast = TabularAutoML(\n",
    "    task=task,\n",
    "    timeout=300,\n",
    "    cpu_limit=-1,\n",
    "    reader_params={\n",
    "        'n_jobs': 4,\n",
    "        'random_state': 42\n",
    "    }\n",
    ")\n",
    "\n",
    "oof_pred_fast = automl_fast.fit_predict(\n",
    "    X_train[FEATURES + [TARGET]],\n",
    "    roles={'target': TARGET},\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Предсказание на validation\n",
    "val_pred_fast = automl_fast.predict(X_val[FEATURES]).data[:, 0]\n",
    "mae_fast = np.mean(np.abs(X_val[TARGET] - val_pred_fast))\n",
    "print(f\"\\nMAE (Config 1): {mae_fast:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abe820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission сохранен: 4024000 строк\n",
      "   id  pressure\n",
      "0   1  6.283615\n",
      "1   2  5.924276\n",
      "2   3  7.128025\n",
      "3   4  8.029167\n",
      "4   5  9.680011\n"
     ]
    }
   ],
   "source": [
    "# Предсказание на тест\n",
    "test_pred_fast = automl_fast.predict(test[FEATURES]).data[:, 0]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'pressure': test_pred_fast\n",
    "})\n",
    "\n",
    "submission.to_csv('submissions/lama_config1_submission.csv', index=False)\n",
    "print(f\"Submission сохранен: {len(submission)} строк\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b3149",
   "metadata": {},
   "source": [
    "##### **Config_2. LAMA бейзлайн – DEEP + split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15603ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAMA CONFIG 2: LONG (1800 sec)\n",
      "[17:00:30] Stdout logging level is INFO.\n",
      "[17:00:30] Task: reg\n",
      "\n",
      "[17:00:30] Start automl preset with listed constraints:\n",
      "[17:00:30] - time: 1800.00 seconds\n",
      "[17:00:30] - CPU: 11 cores\n",
      "[17:00:30] - memory: 16 GB\n",
      "\n",
      "[17:00:30] \u001b[1mTrain data shape: (4828800, 6)\u001b[0m\n",
      "\n",
      "[17:00:34] Layer \u001b[1m1\u001b[0m train process start. Time left 1795.54 secs\n",
      "[17:02:02] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:02:02] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n",
      "[17:09:11] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-1.9253601835955747\u001b[0m\n",
      "[17:09:11] \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:09:11] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m ...\n",
      "[17:18:49] Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m finished. score = \u001b[1m-2.1692255966336558\u001b[0m\n",
      "[17:18:49] \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:18:49] Time left 700.62 secs\n",
      "\n",
      "[17:18:49] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:18:49] Blending: optimization starts with equal weights. Score = \u001b[1m-2.0114945\u001b[0m\n",
      "[17:18:50] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-1.9253602\u001b[0m, weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[17:18:50] Blending: no improvements for score. Terminated.\n",
      "\n",
      "[17:18:50] Blending: best score = \u001b[1m-1.9253602\u001b[0m, best weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[17:18:50] \u001b[1mAutoml preset training completed in 1100.35 seconds\u001b[0m\n",
      "\n",
      "[17:18:50] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) \n",
      "\n",
      "\n",
      "MAE (Config 2): 1.9093\n"
     ]
    }
   ],
   "source": [
    "print(\"LAMA CONFIG 2: LONG (1800 sec)\")\n",
    "\n",
    "automl_deep = TabularAutoML(\n",
    "    task=task,\n",
    "    timeout=1800,\n",
    "    cpu_limit=-1,\n",
    "    general_params={\n",
    "        'use_algos': [['lgb', 'cb']]\n",
    "    },\n",
    "    reader_params={\n",
    "        'n_jobs': 4,\n",
    "        'random_state': 42\n",
    "    }\n",
    ")\n",
    "\n",
    "oof_pred_deep = automl_deep.fit_predict(\n",
    "    X_train[FEATURES + [TARGET]],\n",
    "    roles={'target': TARGET},\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_pred_deep = automl_deep.predict(X_val[FEATURES]).data[:, 0]\n",
    "mae_deep = np.mean(np.abs(X_val[TARGET] - val_pred_deep))\n",
    "print(f\"\\nMAE (Config 2): {mae_deep:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebe1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission сохранен: 4024000 строк\n",
      "   id  pressure\n",
      "0   1  6.245288\n",
      "1   2  5.945842\n",
      "2   3  7.185876\n",
      "3   4  8.135557\n",
      "4   5  9.929556\n"
     ]
    }
   ],
   "source": [
    "# Предсказание на тест\n",
    "test_pred_deep = automl_deep.predict(test[FEATURES]).data[:, 0]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'pressure': test_pred_deep\n",
    "})\n",
    "\n",
    "submission.to_csv('submissions/lama_config2_submission.csv', index=False)\n",
    "print(f\"Submission сохранен: {len(submission)} строк\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100d860",
   "metadata": {},
   "source": [
    "### Промеждуточные результаты экспериментов - LAMA baseline на 2 конфигурациях\n",
    "\n",
    "| Конфигурация | Time limit | Алгоритмы (фактически) | Validation MAE | Kaggle Public | Комментарий |\n",
    "|---|---|---|---|---|---|\n",
    "| **Config 1 (Fast + split)** | 300 sec | LightGBM | **1.92** | 3.78 | Быстрое обучение, базовый уровень качества |\n",
    "| **Config 2 (Deep + split)** | 1800 sec | LGBM + CatBoost | 1.85 | **3.74** | Более стабильная модель, чуть лучше Kaggle score |\n",
    "\n",
    "\n",
    "Не устроило качество, решила эксперементировать дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c4b00",
   "metadata": {},
   "source": [
    "##### **Config_3. LAMA бейзлайн – FAST**\n",
    "Попробуем не делить данные с учетом временных рядов индентификатора, протестируем аналогично, но на стандартном train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ea9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "sample = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "print(f\"Размер тренировочной выборки: {train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {test.shape}\")\n",
    "print(f\"Размер sample выборки: {sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00542f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_BASE = ['R', 'C', 'time_step', 'u_in', 'u_out']\n",
    "TARGET = 'pressure'\n",
    "\n",
    "roles = {\n",
    "    'target': TARGET,\n",
    "    'drop': ['breath_id']\n",
    "}\n",
    "\n",
    "task = Task('reg', metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea676aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:27:24] Stdout logging level is INFO2.\n",
      "[15:27:24] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[15:27:24] Task: reg\n",
      "\n",
      "[15:27:24] Start automl preset with listed constraints:\n",
      "[15:27:24] - time: 300.00 seconds\n",
      "[15:27:24] - CPU: 11 cores\n",
      "[15:27:24] - memory: 16 GB\n",
      "\n",
      "[15:27:24] \u001b[1mTrain data shape: (6036000, 6)\u001b[0m\n",
      "\n",
      "[15:27:28] Layer \u001b[1m1\u001b[0m train process start. Time left 296.46 secs\n",
      "[15:27:28] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[15:27:28] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[15:28:13] Time limit exceeded after calculating fold 0\n",
      "\n",
      "[15:28:13] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-3.849488213242899\u001b[0m\n",
      "[15:28:13] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[15:28:13] Time left 251.02 secs\n",
      "\n",
      "[15:29:46] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:29:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[15:29:47] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[15:31:20] Time limit exceeded after calculating fold 0\n",
      "\n",
      "[15:31:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-1.9261782002405154\u001b[0m\n",
      "[15:31:20] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:31:20] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[15:31:20] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[15:33:39] Time limit exceeded after calculating fold 0\n",
      "\n",
      "[15:33:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-2.168195780720821\u001b[0m\n",
      "[15:33:39] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:33:39] Time left -74.72 secs\n",
      "\n",
      "[15:33:39] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n",
      "[15:33:39] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:33:39] Blending: optimization starts with equal weights. Score = \u001b[1m-2.4167436\u001b[0m\n",
      "[15:33:41] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-1.9261782\u001b[0m, weights = \u001b[1m[0. 1. 0.]\u001b[0m\n",
      "[15:33:42] Blending: no improvements for score. Terminated.\n",
      "\n",
      "[15:33:42] Blending: best score = \u001b[1m-1.9261782\u001b[0m, best weights = \u001b[1m[0. 1. 0.]\u001b[0m\n",
      "[15:33:42] \u001b[1mAutoml preset training completed in 377.92 seconds\u001b[0m\n",
      "\n",
      "[15:33:42] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "automl_base = TabularAutoML(\n",
    "    task=task,\n",
    "    timeout=300,\n",
    "    cpu_limit=-1,\n",
    "    reader_params={\n",
    "        'n_jobs': 4,\n",
    "        'random_state': 42\n",
    "    }\n",
    ")\n",
    "\n",
    "oof_base = automl_base.fit_predict(\n",
    "    train[FEATURES_BASE + [TARGET]],\n",
    "    roles=roles,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2be309",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_base = automl_base.predict(test[FEATURES_BASE]).data[:, 0]\n",
    "\n",
    "submission_base = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'pressure': test_pred_base\n",
    "})\n",
    "\n",
    "submission_base.to_csv('submissions/lama_config_fast_baseline.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e01a6",
   "metadata": {},
   "source": [
    "##### **Config_4. LAMA бейзлайн – DEEP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:41:38] Stdout logging level is INFO2.\n",
      "[15:41:38] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[15:41:38] Task: reg\n",
      "\n",
      "[15:41:38] Start automl preset with listed constraints:\n",
      "[15:41:38] - time: 1800.00 seconds\n",
      "[15:41:38] - CPU: 11 cores\n",
      "[15:41:38] - memory: 16 GB\n",
      "\n",
      "[15:41:38] \u001b[1mTrain data shape: (6036000, 6)\u001b[0m\n",
      "\n",
      "[15:41:41] Layer \u001b[1m1\u001b[0m train process start. Time left 1796.91 secs\n",
      "[15:43:12] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:43:13] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n",
      "[15:43:13] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[15:44:44] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[15:46:19] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[15:47:51] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[15:49:23] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[15:50:55] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-1.9235735844317972\u001b[0m\n",
      "[15:50:55] \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:50:55] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m ...\n",
      "[15:50:55] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[15:53:11] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[15:55:25] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[15:57:38] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[15:59:49] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[16:02:01] Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m finished. score = \u001b[1m-2.1703995970404497\u001b[0m\n",
      "[16:02:01] \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m fitting and predicting completed\n",
      "[16:02:01] Time left 577.04 secs\n",
      "\n",
      "[16:02:01] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[16:02:01] Blending: optimization starts with equal weights. Score = \u001b[1m-2.0112211\u001b[0m\n",
      "[16:02:01] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-1.9235736\u001b[0m, weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[16:02:02] Blending: no improvements for score. Terminated.\n",
      "\n",
      "[16:02:02] Blending: best score = \u001b[1m-1.9235736\u001b[0m, best weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[16:02:02] \u001b[1mAutoml preset training completed in 1224.07 seconds\u001b[0m\n",
      "\n",
      "[16:02:02] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "automl_deep = TabularAutoML(\n",
    "    task=task,\n",
    "    timeout=1800,\n",
    "    cpu_limit=-1,\n",
    "    general_params={\n",
    "        'use_algos': [['lgb', 'cb']] # LightGBM и CatBoost\n",
    "    },\n",
    "    reader_params={\n",
    "        'n_jobs': 4,\n",
    "        'random_state': 42\n",
    "    }\n",
    ")\n",
    "\n",
    "oof_base = automl_deep.fit_predict(\n",
    "    train[FEATURES_BASE + [TARGET]],\n",
    "    roles=roles,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a57cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_base = automl_deep.predict(test[FEATURES_BASE]).data[:, 0]\n",
    "\n",
    "submission_base = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'pressure': test_pred_base\n",
    "})\n",
    "submission_base.to_csv('submissions/lama_config_deep_baseline.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef1dd7",
   "metadata": {},
   "source": [
    "##### **Config_3. LAMA бейзлайн – DEEP + FE**\n",
    "На этапе eda сформировался стек FE признаков, которые полезно было бы добавить. Попробуем обучит LAMA с дополнительными FE:\n",
    "**1. Lag-признаки**\n",
    "- `u_in_lag_1/2/3` - предыдущие значения управляющего сигнала\n",
    "- так как корреляция внутри циклов в 2-3 раза сильнее глобальной\n",
    "\n",
    "**2. Difference признаки**\n",
    "- `u_in_diff` - скорость изменения управляющего сигнала\n",
    "- динамика изменений критична для временных моделей\n",
    "\n",
    "**3. Cumulative sum**\n",
    "- `u_in_cumsum` - накопленный объем воздуха\n",
    "-  физический смысл - интеграл потока\n",
    "\n",
    "**4. Взаимодействия R×C**\n",
    "- `R_x_C` - произведение параметров легких\n",
    "- график показал нелинейное влияние комбинаций\n",
    "\n",
    "**5. Позиция в цикле**\n",
    "- `time_position` - порядковый номер шага внутри breath_id (0-79)\n",
    "- позволяет модели определять фазу дыхания независимо от абсолютного времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208e247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего признаков: 12\n",
      "   Оригинальные: 5\n",
      "   Новые: 7\n",
      "\n",
      "Новые признаки: ['u_in_lag_1', 'u_in_lag_2', 'u_in_lag_3', 'u_in_diff', 'u_in_cumsum', 'R_x_C', 'time_position']\n"
     ]
    }
   ],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Создание признаков на основе анализа:\n",
    "    - Lag features\n",
    "    - Difference\n",
    "    - Cumulative sum\n",
    "    - R×C interaction\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    for lag in [1, 2, 3]:\n",
    "        df[f'u_in_lag_{lag}'] = df.groupby('breath_id')['u_in'].shift(lag)\n",
    "\n",
    "    df['u_in_diff'] = df.groupby('breath_id')['u_in'].diff()\n",
    "    df['u_in_cumsum'] = df.groupby('breath_id')['u_in'].cumsum()\n",
    "    df['R_x_C'] = df['R'] * df['C']\n",
    "    df['time_position'] = df.groupby('breath_id').cumcount()\n",
    "    \n",
    "    # Заполнение NaN в lag-признаках нулями\n",
    "    lag_cols = [f'u_in_lag_{i}' for i in [1, 2, 3]] + ['u_in_diff']\n",
    "    df[lag_cols] = df[lag_cols].fillna(0)\n",
    "    \n",
    "    print(f\"Created {len(lag_cols) + 3} new features\")\n",
    "    return df\n",
    "\n",
    "# Список всех признаков\n",
    "ORIGINAL_FEATURES = ['R', 'C', 'time_step', 'u_in', 'u_out']\n",
    "NEW_FEATURES = ['u_in_lag_1', 'u_in_lag_2', 'u_in_lag_3', \n",
    "                'u_in_diff', 'u_in_cumsum', 'R_x_C', 'time_position']\n",
    "ALL_FEATURES = ORIGINAL_FEATURES + NEW_FEATURES\n",
    "\n",
    "print(f\"Всего признаков: {len(ALL_FEATURES)}\")\n",
    "print(f\"   Оригинальные: {len(ORIGINAL_FEATURES)}\")\n",
    "print(f\"   Новые: {len(NEW_FEATURES)}\")\n",
    "print(f\"\\nНовые признаки: {NEW_FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 7 new features\n",
      "Created 7 new features\n"
     ]
    }
   ],
   "source": [
    "train_fe = create_features(train)\n",
    "test_fe  = create_features(test)\n",
    "\n",
    "FEATURES = ['R','C','time_step','u_in','u_out','u_in_lag_1','u_in_lag_2','u_in_lag_3',\n",
    "            'u_in_diff','u_in_cumsum','R_x_C','time_position']\n",
    "TARGET = 'pressure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576ecc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:05:31] Stdout logging level is INFO2.\n",
      "[23:05:31] Task: reg\n",
      "\n",
      "[23:05:31] Start automl preset with listed constraints:\n",
      "[23:05:31] - time: 1800.00 seconds\n",
      "[23:05:31] - CPU: 11 cores\n",
      "[23:05:31] - memory: 16 GB\n",
      "\n",
      "[23:05:31] \u001b[1mTrain data shape: (6036000, 13)\u001b[0m\n",
      "\n",
      "[23:05:36] Layer \u001b[1m1\u001b[0m train process start. Time left 1795.03 secs\n",
      "[23:07:26] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[23:07:28] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n",
      "[23:07:28] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[23:09:12] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[23:10:58] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[23:12:45] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[23:14:30] Time limit exceeded after calculating fold 3\n",
      "\n",
      "[23:14:30] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.5233867584469205\u001b[0m\n",
      "[23:14:30] \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[23:14:30] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m ...\n",
      "[23:14:30] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[23:16:55] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[23:19:20] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[23:21:47] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[23:24:10] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m =====\n",
      "[23:26:36] Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m finished. score = \u001b[1m-0.8413168375172477\u001b[0m\n",
      "[23:26:36] \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m fitting and predicting completed\n",
      "[23:26:36] Time left 535.19 secs\n",
      "\n",
      "[23:26:36] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[23:26:36] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[23:26:36] Blending: optimization starts with equal weights. Score = \u001b[1m-0.6829547\u001b[0m\n",
      "[23:26:37] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.5233868\u001b[0m, weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[23:26:37] Blending: no improvements for score. Terminated.\n",
      "\n",
      "[23:26:37] Blending: best score = \u001b[1m-0.5233868\u001b[0m, best weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[23:26:37] \u001b[1mAutoml preset training completed in 1266.14 seconds\u001b[0m\n",
      "\n",
      "[23:26:37] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (4 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "automl_deep_fe = TabularAutoML(\n",
    "    task=task,\n",
    "    timeout=1800,\n",
    "    cpu_limit=-1,\n",
    "    general_params={\n",
    "        'use_algos': [['lgb', 'cb']] # LightGBM и CatBoost\n",
    "    },\n",
    "    reader_params={\n",
    "        'n_jobs': 4,\n",
    "        'random_state': 42\n",
    "    }\n",
    ")\n",
    "\n",
    "oof_base = automl_deep_fe.fit_predict(\n",
    "    train_fe[FEATURES + [TARGET]],\n",
    "    roles=roles,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae86ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_base = automl_deep_fe.predict(test_fe[FEATURES]).data[:, 0]\n",
    "\n",
    "submission_base = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'pressure': test_pred_base\n",
    "})\n",
    "submission_base.to_csv('submissions/lama_config_deep_fe_baseline.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e55e0",
   "metadata": {},
   "source": [
    "### Итоговые результаты экспериментов - LAMA baseline на 5 конфигурациях\n",
    "\n",
    "| Конфигурация | Time limit | Алгоритмы (фактически) |  Kaggle Private Score |Kaggle Public Score |\n",
    "|---|---|---|---|---|\n",
    "| **Config 1 (Fast + split)** | 300 sec | LightGBM |  3.7592 |  3.7776 |\n",
    "| **Config 2 (Deep + split)** | 1800 sec | LGBM + CatBoost | 3.7262 |  3.7450   |\n",
    "| **Config 3 (Fast)** | 300 sec | LightGBM |  3.7609 |  3.7813  |\n",
    "| **Config 4 (Deep)** | 1800 sec | LGBM + CatBoost | 3.7292 | 3.7487 |\n",
    "| **Config 5 (Deep + fe)** | 1800 sec | LGBM + CatBoost | **0.8491** | **0.8480** |\n",
    "\n",
    "Лучшим результатом среди всех LAMA оказался с добавляением FE. \n",
    "Попробуем побить его в custom_solition.ipynb!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ventilator-pressure-prediction-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
